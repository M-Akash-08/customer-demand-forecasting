
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering for Sales Forecasting\n",
        "## Creating Time-Based Features for Predictive Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Import Libraries and Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the sales data\n",
        "df = pd.read_csv(\"data/sales.csv\")\n",
        "\n",
        "# Display initial shape\n",
        "print(f\"Initial dataset shape: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert date column to datetime format\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# Sort by date to ensure proper time series order\n",
        "df = df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "print(\"Data sorted by date\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Lag Features\n",
        "Create lag features to capture historical sales patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create lag features (previous time periods)\n",
        "df['lag_1'] = df['sales'].shift(1)  # Previous day/period sales\n",
        "df['lag_3'] = df['sales'].shift(3)  # Sales from 3 periods ago\n",
        "\n",
        "print(\"Lag features created\")\n",
        "df[['date', 'sales', 'lag_1', 'lag_3']].head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Rolling Window Statistics\n",
        "Calculate moving averages and standard deviations to capture trends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rolling mean - captures short-term trends\n",
        "df['rolling_mean_3'] = df['sales'].rolling(window=3).mean()\n",
        "\n",
        "# Rolling standard deviation - captures volatility\n",
        "df['rolling_std_3'] = df['sales'].rolling(window=3).std()\n",
        "\n",
        "print(\"Rolling statistics calculated\")\n",
        "df[['date', 'sales', 'rolling_mean_3', 'rolling_std_3']].head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Calendar-Based Features\n",
        "Extract temporal patterns from date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract month and quarter for seasonality\n",
        "df['month'] = df['date'].dt.month\n",
        "df['quarter'] = df['date'].dt.quarter\n",
        "\n",
        "# Optional: Add more calendar features\n",
        "df['day_of_week'] = df['date'].dt.dayofweek\n",
        "df['day_of_month'] = df['date'].dt.day\n",
        "df['week_of_year'] = df['date'].dt.isocalendar().week\n",
        "\n",
        "print(\"Calendar features extracted\")\n",
        "df[['date', 'sales', 'month', 'quarter', 'day_of_week']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Handle Missing Values\n",
        "Remove rows with NaN values created by lag and rolling features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check missing values before cleaning\n",
        "print(\"Missing values before cleaning:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nDataset shape before: {df.shape}\")\n",
        "\n",
        "# Remove rows with NaN values\n",
        "df = df.dropna()\n",
        "\n",
        "print(f\"\\nDataset shape after: {df.shape}\")\n",
        "print(f\"Rows removed: {df.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Final Feature Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display final engineered features\n",
        "print(\"Final feature set:\")\n",
        "print(df.columns.tolist())\n",
        "print(f\"\\nTotal features: {df.shape[1]}\")\n",
        "print(f\"Total samples: {df.shape[0]}\")\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. Feature Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary of engineered features\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9. Save Processed Data (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the feature-engineered dataset\n",
        "# df.to_csv('data/sales_features.csv', index=False)\n",
        "# print(\"Processed data saved to 'data/sales_features.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary of Engineered Features\n",
        "\n",
        "**Lag Features:**\n",
        "- `lag_1`: Sales from previous period (captures immediate past)\n",
        "- `lag_3`: Sales from 3 periods ago (captures weekly/short-term patterns)\n",
        "\n",
        "**Rolling Statistics:**\n",
        "- `rolling_mean_3`: 3-period moving average (smooths out noise)\n",
        "- `rolling_std_3`: 3-period standard deviation (captures volatility)\n",
        "\n",
        "**Calendar Features:**\n",
        "- `month`: Month of year (1-12) for seasonal patterns\n",
        "- `quarter`: Quarter of year (1-4) for quarterly trends\n",
        "- `day_of_week`: Day of week (0=Monday, 6=Sunday)\n",
        "- `day_of_month`: Day within month (1-31)\n",
        "- `week_of_year`: Week number (1-52)\n",
        "\n",
        "**Next Steps:**\n",
        "1. Train-test split\n",
        "2. Feature scaling/normalization\n",
        "3. Model training (Linear Regression, Random Forest, XGBoost)\n",
        "4. Model evaluation and comparison"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
