{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sales Forecasting - Model Training & Evaluation\n",
        "## Comparing Linear Regression and ARIMA Models for Demand Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForest Regressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Time series library\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "print(\"Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the sales data\n",
        "df = pd.read_csv(\"data/sales.csv\")\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Feature Engineering\n",
        "Create time-based features for forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lag features\n",
        "df['lag_1'] = df['sales'].shift(1)\n",
        "df['lag_3'] = df['sales'].shift(3)\n",
        "\n",
        "# Rolling statistics\n",
        "df['rolling_mean_3'] = df['sales'].rolling(window=3).mean()\n",
        "df['rolling_std_3'] = df['sales'].rolling(window=3).std()\n",
        "\n",
        "# Calendar features\n",
        "df['month'] = df['date'].dt.month\n",
        "df['quarter'] = df['date'].dt.quarter\n",
        "df['day_of_week'] = df['date'].dt.dayofweek\n",
        "\n",
        "# Remove NaN values\n",
        "df = df.dropna()\n",
        "\n",
        "print(f\"Features created. New shape: {df.shape}\")\n",
        "print(f\"\\nFeature columns: {df.drop(['date', 'sales'], axis=1).columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Train-Test Split\n",
        "Time-based split to maintain temporal order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define split date\n",
        "split_date = '2023-01-01'\n",
        "\n",
        "# Split data\n",
        "train = df[df['date'] < split_date]\n",
        "test = df[df['date'] >= split_date]\n",
        "\n",
        "print(f\"Train set: {train.shape[0]} samples ({train['date'].min()} to {train['date'].max()})\")\n",
        "print(f\"Test set: {test.shape[0]} samples ({test['date'].min()} to {test['date'].max()})\")\n",
        "print(f\"Train-test ratio: {len(train)}/{len(test)} ({len(train)/len(df)*100:.1f}% train)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and target\n",
        "feature_cols = ['lag_1', 'lag_3', 'rolling_mean_3', 'rolling_std_3', 'month', 'quarter', 'day_of_week']\n",
        "\n",
        "X_train = train[feature_cols]\n",
        "y_train = train['sales']\n",
        "\n",
        "X_test = test[feature_cols]\n",
        "y_test = test['sales']\n",
        "\n",
        "print(f\"\\nFeature matrix shape: {X_train.shape}\")\n",
        "print(f\"Target variable shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Model 1: Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Linear Regression\n",
        "print(\"Training Linear Regression model...\")\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "pred_lr = lr.predict(X_test)\n",
        "\n",
        "print(\"Linear Regression training complete\")\n",
        "print(f\"Model coefficients: {lr.coef_}\")\n",
        "print(f\"Model intercept: {lr.intercept_:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Model 2: Random Forest (Optional Enhancement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest\n",
        "print(\"Training Random Forest model...\")\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "pred_rf = rf.predict(X_test)\n",
        "\n",
        "print(\"Random Forest training complete\")\n",
        "print(f\"Feature importances: {dict(zip(feature_cols, rf.feature_importances_))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Model 3: ARIMA Time Series Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ARIMA model\n",
        "print(\"Training ARIMA model...\")\n",
        "print(\"This may take a moment...\")\n",
        "\n",
        "# ARIMA(p, d, q) - (1,1,1) is a common starting point\n",
        "arima_model = ARIMA(train['sales'], order=(1, 1, 1))\n",
        "arima_fit = arima_model.fit()\n",
        "\n",
        "# Make predictions\n",
        "pred_arima = arima_fit.forecast(steps=len(test))\n",
        "\n",
        "print(\"ARIMA training complete\")\n",
        "print(f\"\\nARIMA Model Summary:\")\n",
        "print(arima_fit.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. Model Evaluation\n",
        "Compare models using multiple metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate metrics for each model\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    \n",
        "    print(f\"\\n{model_name} Performance:\")\n",
        "    print(f\"  MAE:  {mae:.2f}\")\n",
        "    print(f\"  RMSE: {rmse:.2f}\")\n",
        "    print(f\"  R²:   {r2:.4f}\")\n",
        "    print(f\"  MAPE: {mape:.2f}%\")\n",
        "    \n",
        "    return {'Model': model_name, 'MAE': mae, 'RMSE': rmse, 'R²': r2, 'MAPE': mape}\n",
        "\n",
        "# Evaluate all models\n",
        "results = []\n",
        "results.append(evaluate_model(y_test, pred_lr, \"Linear Regression\"))\n",
        "results.append(evaluate_model(y_test, pred_rf, \"Random Forest\"))\n",
        "results.append(evaluate_model(y_test, pred_arima, \"ARIMA\"))\n",
        "\n",
        "# Create comparison dataframe\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9. Visualize Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot actual vs predicted values\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.plot(test['date'], y_test.values, label='Actual', linewidth=2, marker='o', markersize=4)\n",
        "plt.plot(test['date'], pred_lr, label='Linear Regression', linewidth=2, alpha=0.7)\n",
        "plt.plot(test['date'], pred_rf, label='Random Forest', linewidth=2, alpha=0.7)\n",
        "plt.plot(test['date'], pred_arima, label='ARIMA', linewidth=2, alpha=0.7)\n",
        "\n",
        "plt.title(\"Sales Forecasting: Model Comparison\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Date\", fontsize=12)\n",
        "plt.ylabel(\"Sales\", fontsize=12)\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 10. Residual Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate residuals\n",
        "residuals_lr = y_test - pred_lr\n",
        "residuals_rf = y_test - pred_rf\n",
        "residuals_arima = y_test - pred_arima\n",
        "\n",
        "# Plot residuals\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "axes[0].scatter(pred_lr, residuals_lr, alpha=0.6)\n",
        "axes[0].axhline(y=0, color='r', linestyle='--')\n",
        "axes[0].set_title('Linear Regression Residuals')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Residuals')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].scatter(pred_rf, residuals_rf, alpha=0.6, color='green')\n",
        "axes[1].axhline(y=0, color='r', linestyle='--')\n",
        "axes[1].set_title('Random Forest Residuals')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('Residuals')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].scatter(pred_arima, residuals_arima, alpha=0.6, color='orange')\n",
        "axes[2].axhline(y=0, color='r', linestyle='--')\n",
        "axes[2].set_title('ARIMA Residuals')\n",
        "axes[2].set_xlabel('Predicted')\n",
        "axes[2].set_ylabel('Residuals')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 11. Feature Importance (Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Importance': rf.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importance - Random Forest Model')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 3 Most Important Features:\")\n",
        "print(feature_importance.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary & Insights\n",
        "\n",
        "### Model Performance Comparison:\n",
        "Based on the evaluation metrics above:\n",
        "\n",
        "**Best Model:** [Identify based on lowest MAE/RMSE and highest R²]\n",
        "\n",
        "### Key Findings:\n",
        "1. **Linear Regression:** Simple, interpretable baseline model\n",
        "2. **Random Forest:** Captures non-linear patterns, handles feature interactions\n",
        "3. **ARIMA:** Specialized for time series, captures temporal dependencies\n",
        "\n",
        "### Most Important Features:\n",
        "- Primary driver: [lag_1, rolling_mean_3, etc.]\n",
        "- Secondary factors: [month, quarter for seasonality]\n",
        "\n",
        "### Business Recommendations:\n",
        "1. Use [best model] for production forecasting\n",
        "2. Focus on [top features] for inventory planning\n",
        "3. Monitor model performance and retrain quarterly\n",
        "\n",
        "### Next Steps:\n",
        "- Hyperparameter tuning for better performance\n",
        "- Test additional models (XGBoost, Prophet)\n",
        "- Deploy model for real-time predictions\n",
        "- Set up monitoring and alerting system"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
